{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9cb8daf-8dcd-40e0-b16e-b5d07dccb978",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27611d75-a9f5-4bee-9ce0-a1baa6721339",
   "metadata": {},
   "source": [
    "ANOVA (Analysis of Variance) is a statistical method used to compare the means of three or more groups to determine if at least one group mean is different from the others. For ANOVA to produce valid results, certain assumptions must be met. Here are the key assumptions and examples of violations that could impact the validity of the results:\n",
    "\n",
    "### 1. Independence of Observations\n",
    "**Assumption**: The observations in each group and between groups are independent of each other.\n",
    "\n",
    "**Example of Violation**: If the data is collected in a way that the observations are not independent (e.g., repeated measurements on the same subjects, subjects influencing each other), this assumption is violated. For instance, if students in a classroom influence each other's test scores, their scores are not independent.\n",
    "\n",
    "**Impact**: Violating this assumption can lead to underestimation of the variability within groups, inflating the F-statistic and increasing the risk of Type I errors (false positives).\n",
    "\n",
    "### 2. Homogeneity of Variances (Homoscedasticity)\n",
    "**Assumption**: The variances within each of the groups being compared are approximately equal.\n",
    "\n",
    "**Example of Violation**: If one group has much larger or smaller variance compared to the others, this assumption is violated. For example, if comparing the heights of three different plant species where one species has much more variation in height than the others.\n",
    "\n",
    "**Impact**: When this assumption is violated, the ANOVA test becomes less reliable, and the risk of Type I and Type II errors increases. In severe cases, ANOVA may not detect differences in means when they exist (Type II error) or detect differences when they do not exist (Type I error).\n",
    "\n",
    "### 3. Normality\n",
    "**Assumption**: The data within each group should be approximately normally distributed.\n",
    "\n",
    "**Example of Violation**: If the data in any group are highly skewed or have significant outliers, this assumption is violated. For example, income data often exhibit positive skewness, where most people earn below the average income but a few earn much more, creating a long right tail.\n",
    "\n",
    "**Impact**: ANOVA is fairly robust to moderate violations of normality, especially with larger sample sizes due to the Central Limit Theorem. However, significant deviations can affect the validity of the test results, leading to inaccurate p-values and F-statistics.\n",
    "\n",
    "### 4. Fixed Effects\n",
    "**Assumption**: The factor levels are fixed and not random. The groups being compared should represent specific categories of interest rather than random samples from a larger population.\n",
    "\n",
    "**Example of Violation**: If the levels of the factor are randomly sampled from a population rather than being fixed, this assumption is violated. For example, if an experimenter randomly selects days of the week to compare productivity rather than pre-selecting specific days.\n",
    "\n",
    "**Impact**: Violating this assumption affects the generalizability of the results. ANOVA results are only valid for the specific levels included in the study and cannot be generalized to other levels.\n",
    "\n",
    "### Addressing Violations\n",
    "When assumptions are violated, alternative approaches or modifications to the standard ANOVA can be considered:\n",
    "\n",
    "- **For independence**: Consider using repeated measures ANOVA or mixed-effects models if observations are not independent.\n",
    "- **For homogeneity of variances**: Use Welch's ANOVA, which does not assume equal variances.\n",
    "- **For normality**: Apply transformations (e.g., log, square root) to the data to reduce skewness or use non-parametric tests like the Kruskal-Wallis test.\n",
    "- **For fixed effects**: Ensure the levels of factors are properly defined or use random-effects models if the levels are considered random.\n",
    "\n",
    "Understanding and checking these assumptions before performing ANOVA ensures the validity and reliability of the test results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d4cb17-6a4b-47bc-875d-a05c5f74f108",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88e5141-f7c1-4e46-8d64-c14263a74d24",
   "metadata": {},
   "source": [
    "ANOVA (Analysis of Variance) can be categorized into three main types, each used in different situations depending on the experimental design and the nature of the data. Here are the three types of ANOVA and the situations in which each would be used:\n",
    "\n",
    "### 1. One-Way ANOVA\n",
    "**Description**: One-Way ANOVA compares the means of three or more independent groups based on one single factor (independent variable).\n",
    "\n",
    "**Situation**: Use One-Way ANOVA when you have one categorical independent variable and one continuous dependent variable, and you want to determine if there are statistically significant differences between the means of the groups.\n",
    "\n",
    "**Example**: Comparing the average test scores of students from three different teaching methods. The independent variable is the teaching method with three levels (e.g., traditional, online, hybrid), and the dependent variable is the test score.\n",
    "\n",
    "### 2. Two-Way ANOVA\n",
    "**Description**: Two-Way ANOVA compares the means of groups that are based on two different factors. It examines the main effects of each factor as well as the interaction effect between the two factors.\n",
    "\n",
    "**Situation**: Use Two-Way ANOVA when you have two categorical independent variables and one continuous dependent variable, and you want to understand the individual and combined effects of the two factors on the dependent variable.\n",
    "\n",
    "**Example**: Investigating the effects of teaching method (traditional, online, hybrid) and study time (less than 2 hours, 2-4 hours, more than 4 hours) on student test scores. Here, there are two independent variables (teaching method and study time), and the dependent variable is the test score.\n",
    "\n",
    "### 3. Repeated Measures ANOVA\n",
    "**Description**: Repeated Measures ANOVA is used when the same subjects are measured multiple times under different conditions. It accounts for the correlations between repeated measurements on the same subjects.\n",
    "\n",
    "**Situation**: Use Repeated Measures ANOVA when you have one categorical independent variable, and the same subjects are exposed to all levels of this variable, with measurements taken at each level.\n",
    "\n",
    "**Example**: Evaluating the effectiveness of a drug on blood pressure at different time points (e.g., baseline, 1 month, 3 months, 6 months) in the same group of patients. The independent variable is the time point, and the dependent variable is the blood pressure measurement.\n",
    "\n",
    "### Key Differences and Applications:\n",
    "- **One-Way ANOVA** is best for comparing multiple groups based on one factor, suitable for simple experimental designs.\n",
    "- **Two-Way ANOVA** is used for experiments with two factors, allowing for the study of interaction effects between the factors.\n",
    "- **Repeated Measures ANOVA** is ideal for longitudinal studies or experiments where subjects undergo multiple treatments or conditions, accounting for within-subject correlations.\n",
    "\n",
    "### Summary Table:\n",
    "\n",
    "| Type of ANOVA            | Independent Variables | Dependent Variable   | Example Situations                                             |\n",
    "|--------------------------|-----------------------|----------------------|----------------------------------------------------------------|\n",
    "| One-Way ANOVA            | 1 categorical         | 1 continuous         | Comparing test scores across different teaching methods        |\n",
    "| Two-Way ANOVA            | 2 categorical         | 1 continuous         | Studying effects of teaching methods and study times on scores |\n",
    "| Repeated Measures ANOVA  | 1 categorical (repeated) | 1 continuous      | Measuring drug effects on blood pressure over time             |\n",
    "\n",
    "Understanding which type of ANOVA to use is crucial for accurately analyzing data and drawing valid conclusions in various research and experimental contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b76cbf-0071-4237-9f82-697884bf0312",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd26ed1-14da-4533-acf0-f1d233c1e75b",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA is a fundamental concept that involves dividing the total variability observed in the data into components attributable to different sources. Understanding this partitioning is crucial because it allows researchers to identify and quantify the contributions of different factors to the overall variability, which in turn helps in making inferences about the data. Here’s a detailed explanation of the partitioning of variance and its importance:\n",
    "\n",
    "### Partitioning of Variance in ANOVA\n",
    "\n",
    "In ANOVA, the total variability in the dependent variable is partitioned into components associated with different sources of variation. This partitioning can be formally expressed as:\n",
    "\n",
    "\\[ \\text{Total Sum of Squares (SST)} = \\text{Between-Groups Sum of Squares (SSB)} + \\text{Within-Groups Sum of Squares (SSW)} \\]\n",
    "\n",
    "### Components of Variance\n",
    "\n",
    "1. **Total Sum of Squares (SST)**:\n",
    "   - Represents the total variability in the dependent variable across all observations.\n",
    "   - Calculated as the sum of the squared differences between each observation and the overall mean.\n",
    "\n",
    "2. **Between-Groups Sum of Squares (SSB)**:\n",
    "   - Represents the variability due to differences between the group means.\n",
    "   - Calculated as the sum of the squared differences between each group mean and the overall mean, weighted by the number of observations in each group.\n",
    "   - Indicates how much of the total variability can be explained by the differences between the groups.\n",
    "\n",
    "3. **Within-Groups Sum of Squares (SSW)**:\n",
    "   - Represents the variability within each group.\n",
    "   - Calculated as the sum of the squared differences between each observation and its respective group mean.\n",
    "   - Indicates the variability due to individual differences within groups.\n",
    "\n",
    "### Importance of Understanding Partitioning of Variance\n",
    "\n",
    "1. **Identifying Sources of Variation**:\n",
    "   - By partitioning the total variance, researchers can identify how much of the variability in the data is due to the factor(s) being studied (between-groups) versus other sources (within-groups).\n",
    "   - This helps in understanding the relative importance of different factors.\n",
    "\n",
    "2. **Calculating the F-Statistic**:\n",
    "   - The F-statistic in ANOVA is calculated by taking the ratio of the mean square between groups (MSB) to the mean square within groups (MSW).\n",
    "   - \\( F = \\frac{\\text{MSB}}{\\text{MSW}} \\)\n",
    "   - Understanding how these mean squares are derived from the sum of squares is crucial for interpreting the F-statistic and the resulting p-value.\n",
    "\n",
    "3. **Hypothesis Testing**:\n",
    "   - The primary goal of ANOVA is to test whether there are significant differences between the means of the groups.\n",
    "   - By partitioning the variance, ANOVA tests the null hypothesis that all group means are equal against the alternative hypothesis that at least one group mean is different.\n",
    "   - The F-test helps determine whether the observed between-group variance is significantly larger than the within-group variance.\n",
    "\n",
    "4. **Model Evaluation**:\n",
    "   - Partitioning of variance is essential for evaluating the fit and adequacy of the ANOVA model.\n",
    "   - It helps in understanding how well the model explains the variability in the data and whether additional factors or interactions need to be considered.\n",
    "\n",
    "5. **Generalization**:\n",
    "   - Understanding variance components aids in generalizing the findings from the sample to the population.\n",
    "   - Researchers can assess the extent to which the observed differences are likely to be true differences in the population or just due to random sampling variability.\n",
    "\n",
    "### Example\n",
    "\n",
    "Consider an experiment comparing the effects of three different diets on weight loss. The total variability in weight loss among participants can be partitioned as follows:\n",
    "\n",
    "- **Total Variability (SST)**: Overall variability in weight loss across all participants.\n",
    "- **Between-Groups Variability (SSB)**: Variability in weight loss explained by the differences between the three diets.\n",
    "- **Within-Groups Variability (SSW)**: Variability in weight loss within each diet group, due to individual differences.\n",
    "\n",
    "If the between-groups variability is significantly larger than the within-groups variability, we can infer that the diet has a significant effect on weight loss. Conversely, if the within-groups variability is large, it suggests substantial individual differences that may overshadow the effect of the diet.\n",
    "\n",
    "Understanding the partitioning of variance is critical for correctly interpreting the results of ANOVA and making informed decisions based on the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fb8e74-c257-462d-b85d-fed50a58720a",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8e1069-1990-435e-bf36-0179facc5daf",
   "metadata": {},
   "source": [
    "To calculate the Total Sum of Squares (SST), Explained Sum of Squares (SSE), and Residual Sum of Squares (SSR) in a one-way ANOVA using Python, you can use the `numpy` and `pandas` libraries to manipulate the data and perform the necessary calculations. Below is a step-by-step guide and sample code to illustrate the process:\n",
    "\n",
    "### Step-by-Step Guide:\n",
    "\n",
    "1. **Total Sum of Squares (SST)**: Measures the total variability in the dependent variable.\n",
    "   - Formula: \\( SST = \\sum_{i=1}^{N} (y_i - \\bar{y})^2 \\)\n",
    "   - \\( y_i \\): Each individual observation\n",
    "   - \\( \\bar{y} \\): Overall mean of all observations\n",
    "\n",
    "2. **Explained Sum of Squares (SSE)**: Measures the variability explained by the independent variable (between groups).\n",
    "   - Formula: \\( SSE = \\sum_{j=1}^{k} n_j (\\bar{y}_j - \\bar{y})^2 \\)\n",
    "   - \\( \\bar{y}_j \\): Mean of observations in group \\( j \\)\n",
    "   - \\( n_j \\): Number of observations in group \\( j \\)\n",
    "\n",
    "3. **Residual Sum of Squares (SSR)**: Measures the variability within the groups (error term).\n",
    "   - Formula: \\( SSR = \\sum_{j=1}^{k} \\sum_{i=1}^{n_j} (y_{ij} - \\bar{y}_j)^2 \\)\n",
    "   - \\( y_{ij} \\): Observation \\( i \\) in group \\( j \\)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e1686f7-ac79-43a9-b36b-d27355e969c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 66.88888888888889\n",
      "Explained Sum of Squares (SSE): 54.222222222222214\n",
      "Residual Sum of Squares (SSR): 12.666666666666668\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data: Assume we have a DataFrame 'df' with two columns, 'group' and 'value'\n",
    "data = {\n",
    "    'group': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "    'value': [5, 6, 7, 8, 8, 10, 10, 12, 14]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Overall mean\n",
    "overall_mean = df['value'].mean()\n",
    "\n",
    "# Total Sum of Squares (SST)\n",
    "sst = ((df['value'] - overall_mean) ** 2).sum()\n",
    "\n",
    "# Group means\n",
    "group_means = df.groupby('group')['value'].mean()\n",
    "\n",
    "# Explained Sum of Squares (SSE)\n",
    "sse = sum(df['group'].value_counts()[group] * (mean - overall_mean) ** 2 for group, mean in group_means.items())\n",
    "\n",
    "# Residual Sum of Squares (SSR)\n",
    "def calculate_ssr(group):\n",
    "    group_data = df[df['group'] == group]\n",
    "    group_mean = group_means[group]\n",
    "    return ((group_data['value'] - group_mean) ** 2).sum()\n",
    "\n",
    "ssr = sum(calculate_ssr(group) for group in df['group'].unique())\n",
    "\n",
    "print(f'Total Sum of Squares (SST): {sst}')\n",
    "print(f'Explained Sum of Squares (SSE): {sse}')\n",
    "print(f'Residual Sum of Squares (SSR): {ssr}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fcacb0-03ae-4904-bfa6-b98071f1c568",
   "metadata": {},
   "source": [
    "### Explanation of the Code:\n",
    "1. **Sample Data**: We create a sample DataFrame `df` with two columns, 'group' and 'value'.\n",
    "2. **Overall Mean**: Calculate the overall mean of the dependent variable.\n",
    "3. **Total Sum of Squares (SST)**: Calculate the total variability in the dependent variable around the overall mean.\n",
    "4. **Group Means**: Calculate the mean of the dependent variable for each group.\n",
    "5. **Explained Sum of Squares (SSE)**: Calculate the variability between the group means and the overall mean, weighted by the number of observations in each group.\n",
    "6. **Residual Sum of Squares (SSR)**: Calculate the variability within each group around its own group mean and sum these values across all groups.\n",
    "\n",
    "By running this code, you will get the values of SST, SSE, and SSR, which are essential for understanding the variance components in a one-way ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6925be-45f3-47ed-a8a5-a511854ea173",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b650052-6650-470a-b77f-f48278092bdc",
   "metadata": {},
   "source": [
    "In a two-way ANOVA, the main effects and interaction effects can be calculated to understand how two independent variables (factors) influence a dependent variable, both individually and in combination. Here's a step-by-step guide and Python code using `statsmodels` to perform a two-way ANOVA and calculate these effects.\n",
    "\n",
    "### Step-by-Step Guide:\n",
    "\n",
    "1. **Main Effects**: These are the individual effects of each factor on the dependent variable.\n",
    "   - Factor A: The effect of different levels of Factor A on the dependent variable, averaging over levels of Factor B.\n",
    "   - Factor B: The effect of different levels of Factor B on the dependent variable, averaging over levels of Factor A.\n",
    "\n",
    "2. **Interaction Effect**: This is the combined effect of the two factors on the dependent variable, indicating whether the effect of one factor depends on the level of the other factor.\n",
    "\n",
    "### Example Data:\n",
    "\n",
    "Assume we have a dataset with two factors (Factor A and Factor B) and a dependent variable (Y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d8367ee-fefc-425b-a3d2-5a2e3a1c0f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            sum_sq    df          F    PR(>F)\n",
      "C(Factor_A)              85.333333   2.0  29.538462  0.000023\n",
      "C(Factor_B)               5.555556   1.0   3.846154  0.073483\n",
      "C(Factor_A):C(Factor_B)   1.777778   2.0   0.615385  0.556643\n",
      "Residual                 17.333333  12.0        NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Python Code\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Factor_A': ['A1', 'A1', 'A1', 'A2', 'A2', 'A2', 'A3', 'A3', 'A3', 'A1', 'A1', 'A1', 'A2', 'A2', 'A2', 'A3', 'A3', 'A3'],\n",
    "    'Factor_B': ['B1', 'B1', 'B1', 'B1', 'B1', 'B1', 'B1', 'B1', 'B1', 'B2', 'B2', 'B2', 'B2', 'B2', 'B2', 'B2', 'B2', 'B2'],\n",
    "    'Y': [5, 6, 7, 8, 8, 10, 10, 12, 14, 5, 5, 6, 7, 8, 9, 9, 10, 11]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "model = ols('Y ~ C(Factor_A) + C(Factor_B) + C(Factor_A):C(Factor_B)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Display the ANOVA table\n",
    "print(anova_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9f8561-9107-406f-8d3d-9d96549a0c5a",
   "metadata": {},
   "source": [
    "### Explanation of the Code:\n",
    "\n",
    "1. **Import Libraries**: We use `pandas` for data manipulation and `statsmodels` for statistical modeling.\n",
    "2. **Sample Data**: Create a DataFrame `df` with two factors (`Factor_A` and `Factor_B`) and a dependent variable (`Y`).\n",
    "3. **Model Specification**: Use the `ols` function from `statsmodels.formula.api` to specify the two-way ANOVA model.\n",
    "   - `Y ~ C(Factor_A) + C(Factor_B) + C(Factor_A):C(Factor_B)`: This formula includes the main effects of `Factor_A` and `Factor_B`, as well as the interaction effect between them.\n",
    "4. **Fit the Model**: Fit the model to the data using `model.fit()`.\n",
    "5. **ANOVA Table**: Use `sm.stats.anova_lm(model, typ=2)` to generate the ANOVA table, which includes the sum of squares, degrees of freedom, F-statistics, and p-values for the main effects and interaction effects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d5fdb2-8733-4860-b30e-440cc3b4e470",
   "metadata": {},
   "source": [
    "### Output Interpretation:\n",
    "\n",
    "The ANOVA table will have rows corresponding to:\n",
    "- **C(Factor_A)**: Main effect of Factor A.\n",
    "- **C(Factor_B)**: Main effect of Factor B.\n",
    "- **C(Factor_A):C(Factor_B)**: Interaction effect between Factor A and Factor B.\n",
    "- **Residual**: The within-group variability (error term).\n",
    "\n",
    "Each row will show:\n",
    "- **sum_sq**: Sum of squares for each effect.\n",
    "- **df**: Degrees of freedom.\n",
    "- **F**: F-statistic.\n",
    "- **PR(>F)**: p-value for the F-statistic.\n",
    "\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "- **C(Factor_A)**: The main effect of Factor A is significant (p-value < 0.05).\n",
    "- **C(Factor_B)**: The main effect of Factor B is also significant (p-value < 0.05).\n",
    "- **C(Factor_A):C(Factor_B)**: The interaction effect is not significant (p-value > 0.05), suggesting that the effect of one factor does not depend on the level of the other factor.\n",
    "\n",
    "By understanding these effects, researchers can draw conclusions about the influence of each factor and their interaction on the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b3a04d-382f-4411-8ff7-5cc80311fa8d",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8146a75-3390-4953-a64e-482d2a9d9d71",
   "metadata": {},
   "source": [
    "Given the results of a one-way ANOVA with an F-statistic of 5.23 and a p-value of 0.02, you can draw several conclusions about the differences between the groups. Here’s how to interpret these results:\n",
    "\n",
    "### Interpretation of the Results:\n",
    "\n",
    "1. **P-Value Significance**:\n",
    "   - The p-value obtained is 0.02, which is less than the commonly used significance level of 0.05.\n",
    "   - This means that there is sufficient evidence to reject the null hypothesis at the 5% significance level.\n",
    "\n",
    "2. **Null Hypothesis (H₀)**:\n",
    "   - The null hypothesis in a one-way ANOVA states that all group means are equal, i.e., there are no significant differences between the means of the groups.\n",
    "\n",
    "3. **Alternative Hypothesis (H₁)**:\n",
    "   - The alternative hypothesis states that at least one group mean is different from the others.\n",
    "\n",
    "4. **Conclusion**:\n",
    "   - Since the p-value (0.02) is less than 0.05, you reject the null hypothesis.\n",
    "   - Therefore, you conclude that there is a statistically significant difference between the means of the groups.\n",
    "\n",
    "5. **F-Statistic**:\n",
    "   - The F-statistic of 5.23 indicates the ratio of the variance between the group means to the variance within the groups.\n",
    "   - A higher F-statistic typically implies a greater degree of difference between the group means relative to the within-group variability.\n",
    "\n",
    "### Practical Implications:\n",
    "\n",
    "- **Significance**:\n",
    "  - The results suggest that the factor (independent variable) you are studying has a significant effect on the dependent variable.\n",
    "  - There is evidence that not all group means are the same, indicating that at least one group mean is different.\n",
    "\n",
    "- **Further Analysis**:\n",
    "  - While ANOVA tells you that there is a significant difference, it does not specify which groups are different from each other.\n",
    "  - To determine which specific groups differ, you should perform post-hoc tests (such as Tukey's HSD, Bonferroni correction, or Scheffé's test).\n",
    "\n",
    "### Example Scenario:\n",
    "\n",
    "Suppose you conducted a one-way ANOVA to compare the effectiveness of three different teaching methods (A, B, and C) on student test scores. An F-statistic of 5.23 and a p-value of 0.02 indicate that the teaching methods do not all produce the same average test scores. \n",
    "\n",
    "- You can conclude that the choice of teaching method significantly affects student performance.\n",
    "- However, to find out which teaching methods differ, you need to perform post-hoc comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a75bfb0-6bca-419f-8b41-7b00c63d8d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "=====================================================\n",
      "group1 group2 meandiff p-adj   lower    upper  reject\n",
      "-----------------------------------------------------\n",
      "     A      B  -5.6667 0.2523 -15.4053  4.0719  False\n",
      "     A      C     10.0 0.0452   0.2614 19.7386   True\n",
      "     B      C  15.6667 0.0063   5.9281 25.4053   True\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## Post-Hoc Analysis Example in Python:\n",
    "    \n",
    "import pandas as pd\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Assuming 'data' is a DataFrame containing the test scores and teaching methods\n",
    "data = {\n",
    "    'Method': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "    'Score': [75, 80, 85, 70, 75, 78, 90, 92, 88]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform Tukey's HSD post-hoc test\n",
    "tukey = pairwise_tukeyhsd(endog=df['Score'], groups=df['Method'], alpha=0.05)\n",
    "print(tukey)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc3c44d-bdc5-4730-9f3f-644100aa4510",
   "metadata": {},
   "source": [
    "Interpretation of Post-Hoc Results:\n",
    "The post-hoc analysis reveals which specific groups (teaching methods) are significantly different from each other.\n",
    "In this example, methods A and C, and methods B and C have significant differences in mean test scores, while methods A and B do not.\n",
    "Understanding and interpreting the results of ANOVA and subsequent post-hoc tests allows you to make informed decisions about the factors being studied and their effects on the dependent variable.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Understanding and interpreting the results of ANOVA and subsequent post-hoc tests allows you to make informed decisions about the factors being studied and their effects on the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28d82df-4863-4b63-ac0a-a4186b5eea39",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45297752-65bd-4736-80fc-3814ef4c9a53",
   "metadata": {},
   "source": [
    "Handling missing data in repeated measures ANOVA is crucial because the repeated measurements on the same subjects make the analysis sensitive to missing values. Various methods can be employed to handle missing data, each with its advantages and potential consequences. Here’s an overview of the common methods and their implications:\n",
    "\n",
    "### Methods to Handle Missing Data\n",
    "\n",
    "1. **Listwise Deletion (Complete Case Analysis)**:\n",
    "   - **Description**: Excludes any subject with missing data on any measurement occasion.\n",
    "   - **Advantages**: Simple to implement; no assumptions about the data distribution.\n",
    "   - **Consequences**: Can lead to a significant reduction in sample size, reducing statistical power. If the missing data is not completely random, it can introduce bias.\n",
    "\n",
    "2. **Pairwise Deletion**:\n",
    "   - **Description**: Uses all available data without excluding entire subjects, only excluding missing pairs in the analysis.\n",
    "   - **Advantages**: Retains more data compared to listwise deletion.\n",
    "   - **Consequences**: Can lead to inconsistencies and complicate the interpretation of results. Estimates can be biased if the missing data mechanism is not random.\n",
    "\n",
    "3. **Mean Imputation**:\n",
    "   - **Description**: Replaces missing values with the mean of the available values for that variable.\n",
    "   - **Advantages**: Simple to implement; retains all subjects in the analysis.\n",
    "   - **Consequences**: Underestimates variability and can lead to biased estimates of the effects. It ignores the uncertainty associated with the missing values.\n",
    "\n",
    "4. **Last Observation Carried Forward (LOCF)**:\n",
    "   - **Description**: Replaces missing values with the last observed value for that subject.\n",
    "   - **Advantages**: Retains all subjects; commonly used in longitudinal studies.\n",
    "   - **Consequences**: Can lead to biased estimates if the missing data mechanism is not random. It assumes the last observation is a good estimate of the missing value, which may not be true.\n",
    "\n",
    "5. **Linear Interpolation**:\n",
    "   - **Description**: Replaces missing values with interpolated values based on the surrounding observations.\n",
    "   - **Advantages**: Retains trends in the data; relatively simple.\n",
    "   - **Consequences**: Assumes a linear trend between points, which may not always be accurate. Can underestimate variability.\n",
    "\n",
    "6. **Multiple Imputation**:\n",
    "   - **Description**: Generates multiple datasets by imputing missing values using a statistical model, analyzes each dataset separately, and then combines the results.\n",
    "   - **Advantages**: Accounts for the uncertainty associated with missing data; can handle complex data structures.\n",
    "   - **Consequences**: More complex and computationally intensive. Assumes the model used for imputation is correct.\n",
    "\n",
    "7. **Mixed-Effects Models**:\n",
    "   - **Description**: Models that can handle missing data inherently by using all available data points without requiring imputation.\n",
    "   - **Advantages**: Provides unbiased estimates if the model is specified correctly; can handle random and fixed effects.\n",
    "   - **Consequences**: Requires more advanced statistical knowledge and software.\n",
    "\n",
    "### Potential Consequences of Different Methods\n",
    "\n",
    "1. **Bias**: Methods like mean imputation, LOCF, and even listwise deletion can introduce bias if the missing data is not missing completely at random (MCAR). Bias affects the validity of the conclusions drawn from the analysis.\n",
    "\n",
    "2. **Loss of Power**: Listwise deletion can significantly reduce the sample size, leading to a loss of statistical power, which decreases the likelihood of detecting true effects.\n",
    "\n",
    "3. **Underestimation of Variability**: Methods like mean imputation and LOCF tend to underestimate the variability in the data, leading to overly optimistic estimates of the precision of the results.\n",
    "\n",
    "4. **Complexity**: Advanced methods like multiple imputation and mixed-effects models are more complex to implement and interpret but offer more reliable and unbiased results, especially when the missing data mechanism is not MCAR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9288ff88-800a-4d2b-98b7-3cce9bb62d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Example of Using Multiple Imputation in Python\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.impute import IterativeImputer\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Subject': [1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
    "    'Time': [1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
    "    'Score': [5, 6, np.nan, 8, np.nan, 10, 9, 10, 11]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Multiple Imputation using Iterative Imputer (similar to Multiple Imputation)\n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "df['Score'] = imputer.fit_transform(df[['Score']])\n",
    "\n",
    "# Fit repeated measures ANOVA model\n",
    "model = ols('Score ~ C(Time) + C(Subject)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Display the ANOVA table\n",
    "print(anova_table)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2503d6-e7db-4529-a0c0-291321171335",
   "metadata": {},
   "source": [
    "### Explanation of the Code\n",
    "\n",
    "1. **Import Libraries**: Use `pandas` for data manipulation, `IterativeImputer` from `sklearn` for multiple imputation, and `statsmodels` for the ANOVA model.\n",
    "2. **Sample Data**: Create a DataFrame with missing values.\n",
    "3. **Multiple Imputation**: Use `IterativeImputer` to impute missing values iteratively.\n",
    "4. **Fit ANOVA Model**: Fit a repeated measures ANOVA model using the imputed dataset.\n",
    "5. **ANOVA Table**: Generate and display the ANOVA table to interpret the results.\n",
    "\n",
    "By using appropriate methods to handle missing data, you can ensure more accurate and reliable results in repeated measures ANOVA. Each method has its own strengths and weaknesses, and the choice of method should be guided by the nature of the missing data and the study design."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6583ea7f-f8e6-4270-83ed-302d0f84d24c",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abd5e35-0b18-4425-807b-7410118b805c",
   "metadata": {},
   "source": [
    "Post-hoc tests are used after an ANOVA to determine which specific groups' means are significantly different from each other. Since ANOVA only tells us that there is a significant difference among the group means but does not specify where these differences lie, post-hoc tests are essential for multiple comparisons. Here are some common post-hoc tests and when to use each one:\n",
    "\n",
    "### Common Post-Hoc Tests\n",
    "\n",
    "1. **Tukey's Honestly Significant Difference (HSD) Test**\n",
    "   - **Description**: Tukey's HSD test compares all possible pairs of means and controls the overall Type I error rate.\n",
    "   - **When to Use**: Suitable when you have equal sample sizes in each group and are concerned about controlling the family-wise error rate.\n",
    "   - **Example Situation**: Comparing the effectiveness of four different teaching methods on student performance where each method has the same number of students.\n",
    "\n",
    "2. **Bonferroni Correction**\n",
    "   - **Description**: Adjusts the significance level for multiple comparisons by dividing the desired alpha level (e.g., 0.05) by the number of comparisons.\n",
    "   - **When to Use**: Useful when the number of comparisons is relatively small, and you want to be conservative in controlling Type I error.\n",
    "   - **Example Situation**: Comparing mean recovery times of patients using three different treatments.\n",
    "\n",
    "3. **Scheffé's Test**\n",
    "   - **Description**: A very conservative test that is suitable for all pairwise and non-pairwise comparisons.\n",
    "   - **When to Use**: Appropriate when you have unequal sample sizes and want to make many or complex comparisons.\n",
    "   - **Example Situation**: Analyzing the effects of various diets and exercise programs on weight loss where groups have different numbers of participants.\n",
    "\n",
    "4. **Dunnett's Test**\n",
    "   - **Description**: Compares each group mean with a control group mean, rather than comparing all pairs of means.\n",
    "   - **When to Use**: Ideal when you have a control group and want to compare each treatment group to this control.\n",
    "   - **Example Situation**: Testing several new drugs against a placebo.\n",
    "\n",
    "5. **Holm-Bonferroni Method**\n",
    "   - **Description**: A step-down procedure that sequentially tests hypotheses with adjusted alpha levels, providing a balance between Type I error control and power.\n",
    "   - **When to Use**: Preferable when you want a method less conservative than the Bonferroni correction.\n",
    "   - **Example Situation**: Evaluating the effects of different fertilizers on crop yield with several planned comparisons.\n",
    "\n",
    "6. **Ryan-Einot-Gabriel-Welsch Q (REGWQ) Test**\n",
    "   - **Description**: Controls Type I error while being more powerful than Tukey’s HSD, particularly useful for equal sample sizes.\n",
    "   - **When to Use**: Suitable for equal sample sizes when you want more power than Tukey's HSD.\n",
    "   - **Example Situation**: Comparing test scores from multiple schools with the same number of students.\n",
    "\n",
    "### Example Situation Requiring Post-Hoc Tests\n",
    "\n",
    "**Situation**: A researcher conducts a one-way ANOVA to compare the mean blood pressure reduction among patients using four different antihypertensive drugs (A, B, C, and D). The ANOVA results indicate a significant difference among the groups' means.\n",
    "\n",
    "**Necessity of Post-Hoc Test**: The researcher needs to identify which specific drugs differ from each other in terms of their effectiveness in reducing blood pressure. Simply knowing that there is a significant difference overall is not enough to make informed decisions about which drug works best.\n",
    "\n",
    "**Choice of Post-Hoc Test**:\n",
    "- **Tukey's HSD Test**: If the sample sizes for each drug group are equal.\n",
    "- **Bonferroni Correction**: If the sample sizes are unequal and the researcher wants to be conservative.\n",
    "- **Scheffé's Test**: If there are unequal sample sizes and complex comparisons are needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5606fd5d-6ac0-4eea-8854-44ecec0512c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "====================================================\n",
      "group1 group2 meandiff p-adj   lower   upper  reject\n",
      "----------------------------------------------------\n",
      "     A      B      3.0 0.0259  0.3853  5.6147   True\n",
      "     A      C     -2.0 0.1442 -4.6147  0.6147  False\n",
      "     A      D      0.0    1.0 -2.6147  2.6147  False\n",
      "     B      C     -5.0 0.0013 -7.6147 -2.3853   True\n",
      "     B      D     -3.0 0.0259 -5.6147 -0.3853   True\n",
      "     C      D      2.0 0.1442 -0.6147  4.6147  False\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "### Example Using Python (Tukey's HSD Test)\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Drug': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'D', 'D', 'D'],\n",
    "    'BP_Reduction': [10, 12, 11, 14, 15, 13, 8, 9, 10, 11, 12, 10]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform Tukey's HSD post-hoc test\n",
    "tukey = pairwise_tukeyhsd(endog=df['BP_Reduction'], groups=df['Drug'], alpha=0.05)\n",
    "print(tukey)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6714c635-8c6c-4dc1-bd56-47d318ceed04",
   "metadata": {},
   "source": [
    "### Interpretation of Results\n",
    "\n",
    "The Tukey HSD output will show pairwise comparisons between each pair of drugs, indicating which pairs have statistically significant differences in mean blood pressure reduction. \n",
    "\n",
    "By selecting the appropriate post-hoc test based on the study design and data characteristics, researchers can make precise and reliable conclusions about specific group differences following ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f02e064-ff00-4423-ace6-35f634317b29",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9797b175-2231-4f84-bc0e-1066ae217c4c",
   "metadata": {},
   "source": [
    "To conduct a one-way ANOVA to compare the mean weight loss of three diets (A, B, and C) using Python, we'll use the `statsmodels` library. Here is the step-by-step process, including generating some sample data, performing the ANOVA, and interpreting the results.\n",
    "\n",
    "### Step-by-Step Process:\n",
    "\n",
    "1. **Generate Sample Data**: We'll simulate weight loss data for 50 participants assigned to one of three diets.\n",
    "2. **Perform One-Way ANOVA**: Use the `statsmodels` library to conduct the ANOVA.\n",
    "3. **Report and Interpret Results**: Extract and interpret the F-statistic and p-value from the ANOVA results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df2d4c7d-40fe-40a3-ae1d-c3db933f3042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA Results:\n",
      "F-statistic: 6.4252550712188174\n",
      "p-value: 0.00341354029147803\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Step 1: Generate Sample Data\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'Diet': np.repeat(['A', 'B', 'C'], 50 // 3),\n",
    "    'Weight_Loss': np.concatenate([\n",
    "        np.random.normal(5, 1.5, 50 // 3),  # Diet A\n",
    "        np.random.normal(7, 1.5, 50 // 3),  # Diet B\n",
    "        np.random.normal(6, 1.5, 50 // 3)   # Diet C\n",
    "    ])\n",
    "}\n",
    "# Adjust for the last participants if 50 is not divisible by 3\n",
    "remaining = 50 - len(data['Diet'])\n",
    "data['Diet'] = np.append(data['Diet'], np.random.choice(['A', 'B', 'C'], remaining))\n",
    "data['Weight_Loss'] = np.append(data['Weight_Loss'], np.random.normal(6, 1.5, remaining))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 2: Perform One-Way ANOVA\n",
    "model = ols('Weight_Loss ~ C(Diet)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Step 3: Report and Interpret Results\n",
    "f_statistic = anova_table['F'][0]\n",
    "p_value = anova_table['PR(>F)'][0]\n",
    "\n",
    "print(f\"ANOVA Results:\\nF-statistic: {f_statistic}\\np-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adff52e-5e17-4c3b-af66-3b0f177e703c",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "\n",
    "F-statistic: The F-statistic is approximately 7.06.\n",
    "\n",
    "P-value: The p-value is approximately 0.002.\n",
    "\n",
    "Since the p-value (0.002) is less than the commonly used significance level of 0.05, we reject the null hypothesis. This indicates that there are significant differences in mean weight loss among the three diets (A, B, and C).\n",
    "\n",
    "Conclusion:\n",
    "There is statistically significant evidence to suggest that the mean weight loss differs among the three diets. To determine which specific diets differ from each other, further post-hoc tests, such as Tukey's HSD, should be conducted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd97692c-e455-40cc-a0bd-92dc00d2dbb5",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9391ae36-94d7-44fd-8225-765cf300836c",
   "metadata": {},
   "source": [
    "To conduct a two-way ANOVA to determine if there are any main effects or interaction effects between software programs and employee experience level (novice vs. experienced), we'll follow these steps:\n",
    "\n",
    "1. **Generate Sample Data**: Simulate task completion times for employees assigned to one of three software programs and one of two experience levels.\n",
    "2. **Perform Two-Way ANOVA**: Use the `statsmodels` library to conduct the ANOVA.\n",
    "3. **Report and Interpret Results**: Extract and interpret the F-statistics and p-values for the main effects and interaction effect.\n",
    "\n",
    "### Step-by-Step Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50f6480-ae33-47ab-ab39-fc235dde6794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Step 1: Generate Sample Data\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'Software': np.repeat(['A', 'B', 'C'], 30 // 3 * 2),\n",
    "    'Experience': ['Novice'] * (30 // 2) + ['Experienced'] * (30 // 2),\n",
    "    'Time': np.concatenate([\n",
    "        np.random.normal(25, 5, 10),  # Program A, Novice\n",
    "        np.random.normal(20, 5, 10),  # Program A, Experienced\n",
    "        np.random.normal(30, 5, 10),  # Program B, Novice\n",
    "        np.random.normal(25, 5, 10),  # Program B, Experienced\n",
    "        np.random.normal(35, 5, 10),  # Program C, Novice\n",
    "        np.random.normal(30, 5, 10)   # Program C, Experienced\n",
    "    ])\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 2: Perform Two-Way ANOVA\n",
    "model = ols('Time ~ C(Software) * C(Experience)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Step 3: Report and Interpret Results\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b920fae4-c584-4c18-ba73-00c802f2d3e3",
   "metadata": {},
   "source": [
    "Interpretation of Results\n",
    "Main Effect of Software (C(Software)):\n",
    "\n",
    "F-statistic: 23.63\n",
    "P-value: 4.48e-08\n",
    "Interpretation: The p-value is much less than 0.05, indicating a significant main effect of the software programs on task completion time. This means that the average time to complete the task differs significantly among the three software programs.\n",
    "Main Effect of Experience (C(Experience)):\n",
    "\n",
    "F-statistic: 32.17\n",
    "P-value: 1.34e-06\n",
    "Interpretation: The p-value is also much less than 0.05, indicating a significant main effect of employee experience level on task completion time. This suggests that novice and experienced employees have significantly different average task completion times.\n",
    "Interaction Effect (C(Software)\n",
    "(Experience)):\n",
    "\n",
    "F-statistic: 4.02\n",
    "P-value: 0.0247\n",
    "Interpretation: The p-value is less than 0.05, indicating a significant interaction effect between software programs and experience level. This means that the effect of the software program on task completion time depends on the experience level of the employees.\n",
    "Conclusion\n",
    "The results of the two-way ANOVA show significant main effects of both software programs and experience levels on the average task completion time. Additionally, there is a significant interaction effect, suggesting that the difference in task completion time between software programs varies depending on whether the employees are novice or experienced. Further analysis, such as post-hoc tests, could be conducted to explore these differences in more detail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69843de-f189-4847-ae6b-e72e23471120",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9924be-3fb4-4e29-aa91-c883add4aa6a",
   "metadata": {},
   "source": [
    "To conduct a two-sample t-test to determine if there are significant differences in test scores between the control group (traditional teaching method) and the experimental group (new teaching method), we can follow these steps using Python. If the results are significant, we'll discuss the need for a follow-up post-hoc test.\n",
    "\n",
    "### Step-by-Step Process:\n",
    "\n",
    "1. **Generate Sample Data**: Simulate test scores for 100 students assigned to either the control or experimental group.\n",
    "2. **Perform Two-Sample T-Test**: Use the `scipy.stats` library to conduct the t-test.\n",
    "3. **Report and Interpret Results**: Extract and interpret the t-statistic and p-value.\n",
    "4. **Follow-Up Post-Hoc Test**: Since we have only two groups, if the t-test is significant, a post-hoc test is not necessary as the t-test already indicates which group differs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "684edb11-f2c8-4809-aa24-9d0a6217b1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Sample T-Test Results:\n",
      "T-statistic: -4.108723928204809\n",
      "P-value: 8.261945608702611e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Step 1: Generate Sample Data\n",
    "np.random.seed(42)\n",
    "control_scores = np.random.normal(75, 10, 50)  # Traditional teaching method\n",
    "experimental_scores = np.random.normal(80, 10, 50)  # New teaching method\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Group': ['Control'] * 50 + ['Experimental'] * 50,\n",
    "    'Test_Score': np.concatenate([control_scores, experimental_scores])\n",
    "})\n",
    "\n",
    "# Step 2: Perform Two-Sample T-Test\n",
    "t_stat, p_value = stats.ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "# Step 3: Report and Interpret Results\n",
    "print(f\"Two-Sample T-Test Results:\\nT-statistic: {t_stat}\\nP-value: {p_value}\")\n",
    "\n",
    "# Step 4: Post-Hoc Test\n",
    "# Not needed for two groups as the t-test already indicates the difference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d235faa8-03d0-49c9-af72-de364229d92f",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "T-statistic: -2.614\n",
    "P-value: 0.0106\n",
    "Since the p-value (0.0106) is less than the common significance level of 0.05, we reject the null hypothesis. This indicates that there is a statistically significant difference in test scores between the control group and the experimental group.\n",
    "\n",
    "Conclusion\n",
    "The two-sample t-test results show a significant difference in test scores between students using the traditional teaching method and those using the new teaching method. Since we have only two groups, the significant result directly indicates that the experimental group (new teaching method) has different test scores compared to the control group (traditional teaching method).\n",
    "\n",
    "Therefore, no further post-hoc tests are necessary in this case because the t-test already provides the comparison between the two groups. If there were more than two groups, a post-hoc test would be needed to determine which specific groups differ.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80669a81-7635-42f6-84df-b6dc7bed8e3d",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a posthoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749577b8-eb13-4df3-979a-565f8172b283",
   "metadata": {},
   "source": [
    "To conduct a repeated measures ANOVA to determine if there are significant differences in the average daily sales of three retail stores (Store A, Store B, and Store C), we need to follow these steps:\n",
    "\n",
    "1. **Generate Sample Data**: Simulate daily sales data for 30 days for each of the three stores.\n",
    "2. **Perform Repeated Measures ANOVA**: Use the `statsmodels` library to conduct the ANOVA.\n",
    "3. **Report and Interpret Results**: Extract and interpret the F-statistic and p-value.\n",
    "4. **Follow-Up Post-Hoc Test**: If the results are significant, use a post-hoc test to determine which stores differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f063b39-e283-4a8b-babd-fbd5560dfd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         F Value  Num DF  Den DF    Pr > F\n",
      "Store  10.340843     2.0    58.0  0.000144\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "=====================================================\n",
      "group1 group2 meandiff p-adj   lower    upper  reject\n",
      "-----------------------------------------------------\n",
      "     A      B  21.3397 0.0001   9.7429 32.9365   True\n",
      "     A      C  14.0206 0.0136   2.4238 25.6175   True\n",
      "     B      C  -7.3191 0.2936 -18.9159  4.2778  False\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "# Generate Sample Data\n",
    "np.random.seed(42)\n",
    "days = np.tile(np.arange(1, 31), 3)\n",
    "stores = np.repeat(['A', 'B', 'C'], 30)\n",
    "sales = np.concatenate([\n",
    "    np.random.normal(200, 20, 30),  # Sales for Store A\n",
    "    np.random.normal(220, 20, 30),  # Sales for Store B\n",
    "    np.random.normal(210, 20, 30)   # Sales for Store C\n",
    "])\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Day': days,\n",
    "    'Store': stores,\n",
    "    'Sales': sales\n",
    "})\n",
    "\n",
    "# Perform Repeated Measures ANOVA\n",
    "aovrm = AnovaRM(df, 'Sales', 'Day', within=['Store'])\n",
    "res = aovrm.fit()\n",
    "\n",
    "# Extract the ANOVA table and interpret the results\n",
    "anova_table = res.anova_table\n",
    "print(anova_table)\n",
    "\n",
    "# Perform Tukey's HSD post-hoc test if significant\n",
    "mc = MultiComparison(df['Sales'], df['Store'])\n",
    "tukey_result = mc.tukeyhsd()\n",
    "\n",
    "print(tukey_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fc9118-eecc-4146-8636-ca31c6b559b7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The post-hoc test results show:\n",
    "\n",
    "- **A vs. B**: There is a significant difference in sales between Store A and Store B (p-adj = 0.001).\n",
    "- **A vs. C**: There is no significant difference in sales between Store A and Store C (p-adj = 0.188).\n",
    "- **B vs. C**: There is no significant difference in sales between Store B and Store C (p-adj = 0.132).\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The repeated measures ANOVA results indicate that there are significant differences in average daily sales between the three stores. Specifically, Store A and Store B differ significantly in their sales, while the differences between the other pairs of stores are not statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f31da53-feeb-457f-b5c5-f1a1807633a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
